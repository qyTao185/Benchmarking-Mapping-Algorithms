{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e5d006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import scanpy as sc\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import diopy\n",
    "working_dir = 'D:/博士/spatialid-main'\n",
    "os.chdir(working_dir)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from basic_model.cell_type_ann_model import DNNModel\n",
    "from basic_model.focal_loss import MultiCEFocalLoss\n",
    "\n",
    "\n",
    "from basic_model.cell_type_ann_model import SpatialModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af094f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_human_CTX.h5\n",
      "  [Data Info] \n",
      " AnnData object with n_obs × n_vars = 17336 × 36517\n",
      "    obs: 'Subclass', 'nFeature', 'nCount'\n",
      "  [After Preprocessing Data Info] \n",
      " AnnData object with n_obs × n_vars = 17336 × 31208\n",
      "    obs: 'Subclass', 'nFeature', 'nCount'\n",
      "    var: 'n_cells'\n",
      "  [2023-08-22 21:59:57 Epoch:   1 Loss: 0.30655, acc: 40.94%]\n",
      "  [2023-08-22 21:59:59 Model is saved in: E:/doctor/自研/mapping/data/20230814final/spatialID/model\\dnn_sc_human_CTX.h5.bgi]\n",
      "  [2023-08-22 22:00:02 Epoch:   2 Loss: 0.21117, acc: 58.45%]\n",
      "  [2023-08-22 22:00:04 Model is saved in: E:/doctor/自研/mapping/data/20230814final/spatialID/model\\dnn_sc_human_CTX.h5.bgi]\n",
      "  [2023-08-22 22:00:07 Epoch:   3 Loss: 0.19495, acc: 60.58%]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 136310784 vs 136310712",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anaconda\\envs\\spatialIDnew\\lib\\site-packages\\torch\\serialization.py:380\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 380\u001b[0m     \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\spatialIDnew\\lib\\site-packages\\torch\\serialization.py:604\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    603\u001b[0m num_bytes \u001b[38;5;241m=\u001b[39m storage\u001b[38;5;241m.\u001b[39mnbytes()\n\u001b[1;32m--> 604\u001b[0m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 228\u001b[0m\n\u001b[0;32m    225\u001b[0m     ann_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    227\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 228\u001b[0m \u001b[43mdnn_workflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43msc_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m             \u001b[49m\u001b[43mann_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmarker_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m             \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdnn_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mdatalist\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.bgi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m             \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:/doctor/自研/mapping/data/20230814final/spatialID/model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m             \u001b[49m\u001b[43mfilter_mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcell_min_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m             \u001b[49m\u001b[43mgene_min_cells\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcell_max_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m98.\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    242\u001b[0m time_diff \u001b[38;5;241m=\u001b[39m end_time\u001b[38;5;241m-\u001b[39mstart_time\n",
      "Cell \u001b[1;32mIn[19], line 183\u001b[0m, in \u001b[0;36mdnn_workflow\u001b[1;34m(data_path, ann_key, marker_genes, batch_size, epochs, gpu, model_name, model_path, filter_mt, cell_min_counts, gene_min_cells, cell_max_counts)\u001b[0m\n\u001b[0;32m    177\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m transform_data_loader(adata, ann_key, marker_genes, batch_size)\n\u001b[0;32m    179\u001b[0m trainer \u001b[38;5;241m=\u001b[39m DNNTrainer(input_dims\u001b[38;5;241m=\u001b[39madata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m    180\u001b[0m                      num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(adata\u001b[38;5;241m.\u001b[39mobs[ann_key]\u001b[38;5;241m.\u001b[39mcat\u001b[38;5;241m.\u001b[39mcategories),\n\u001b[0;32m    181\u001b[0m                      gpu\u001b[38;5;241m=\u001b[39mgpu)\n\u001b[1;32m--> 183\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarker_genes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmarker_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_nums\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_nums\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m              \u001b[49m\u001b[43mlabel_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mosp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m trainer\u001b[38;5;241m.\u001b[39mvalidation(data_loader, osp\u001b[38;5;241m.\u001b[39mjoin(model_path, model_name))\n",
      "Cell \u001b[1;32mIn[19], line 57\u001b[0m, in \u001b[0;36mDNNTrainer.train\u001b[1;34m(self, data_loader, marker_genes, class_nums, batch_size, label_names, epochs, gamma, alpha, path)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(epoch_loss) \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[0;32m     56\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(epoch_loss)\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker_genes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 26\u001b[0m, in \u001b[0;36mDNNTrainer.save_model\u001b[1;34m(self, marker_genes, batch_size, label_names, path)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, marker_genes, batch_size, label_names, path):\n\u001b[0;32m     20\u001b[0m     state \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m     21\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[0;32m     22\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarker_genes\u001b[39m\u001b[38;5;124m'\u001b[39m: marker_genes,\n\u001b[0;32m     23\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m: batch_size,\n\u001b[0;32m     24\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_names\u001b[39m\u001b[38;5;124m'\u001b[39m: label_names\n\u001b[0;32m     25\u001b[0m              }\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Model is saved in: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\spatialIDnew\\lib\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    380\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m--> 381\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    382\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\spatialIDnew\\lib\\site-packages\\torch\\serialization.py:260\u001b[0m, in \u001b[0;36m_open_zipfile_writer_buffer.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_like\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_end_of_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 136310784 vs 136310712"
     ]
    }
   ],
   "source": [
    "\n",
    "class DNNTrainer:\n",
    "    def __init__(self, input_dims, num_classes, gpu):\n",
    "        self.set_device(gpu)\n",
    "        self.set_model(input_dims, hidden_dims=1024, output_dims=num_classes)\n",
    "        self.set_optimizer()\n",
    "\n",
    "    def set_model(self, input_dims, hidden_dims, output_dims):\n",
    "        self.model = DNNModel(input_dims, hidden_dims, output_dims).to(self.device)\n",
    "\n",
    "    def set_optimizer(self):\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "\n",
    "    def set_device(self, gpu=None):\n",
    "        if gpu is not None and torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda:{}\".format(gpu))\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "    def save_model(self, marker_genes, batch_size, label_names, path):\n",
    "        state = {'model': self.model,\n",
    "                 'optimizer': self.optimizer.state_dict(),\n",
    "                 'marker_genes': marker_genes,\n",
    "                 'batch_size': batch_size,\n",
    "                 'label_names': label_names\n",
    "                 }\n",
    "        torch.save(state, path)\n",
    "        print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')} Model is saved in: {path}]\")\n",
    "\n",
    "    def train(self, data_loader, marker_genes=None, class_nums=None, batch_size=4096, label_names=None, epochs=200, gamma=2, alpha=.25, path=\"dnn_CTX_cellbin.bgi\"):\n",
    "        self.model.train()\n",
    "        best_loss = np.inf\n",
    "        for epoch in range(epochs):\n",
    "            epoch_acc = []\n",
    "            epoch_loss = []\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                inputs, targets = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.long().to(self.device)\n",
    "                output = self.model(inputs)\n",
    "                loss = MultiCEFocalLoss(class_num=class_nums, gamma=gamma, alpha=alpha, reduction=\"mean\")(output, targets)\n",
    "                train_loss = loss.item()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total = targets.size(0)\n",
    "                prediction = output.argmax(1)\n",
    "                correct = prediction.eq(targets).sum().item()\n",
    "\n",
    "                accuracy = correct / total * 100.\n",
    "                epoch_acc.append(accuracy)\n",
    "                epoch_loss.append(train_loss)\n",
    "            print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')} Epoch: {epoch+1:3d} Loss: {np.mean(epoch_loss):.5f}, acc: {np.mean(epoch_acc):.2f}%]\")\n",
    "            if np.mean(epoch_loss) < best_loss:\n",
    "                best_loss = np.mean(epoch_loss)\n",
    "                self.save_model(marker_genes, batch_size, label_names, path)\n",
    "\n",
    "    def validation(self, data_loader, model_path):\n",
    "        checkpoint = torch.load(model_path)\n",
    "        label_names = checkpoint['label_names']\n",
    "        dnn_model = checkpoint[\"model\"].to(self.device)\n",
    "        dnn_model.eval()\n",
    "\n",
    "        dnn_predictions = []\n",
    "        val_acc = []\n",
    "        with torch.no_grad():\n",
    "            for idx, data in enumerate(data_loader):\n",
    "                inputs, targets = data\n",
    "                inputs = inputs.to(self.device)\n",
    "                targets = targets.long().to(self.device)\n",
    "                outputs = dnn_model(inputs)\n",
    "                dnn_predictions.append(outputs.detach().cpu().numpy())\n",
    "\n",
    "                total = targets.size(0)\n",
    "                prediction = outputs.argmax(1)\n",
    "                correct = prediction.eq(targets).sum().item()\n",
    "                accuracy = correct / total * 100.\n",
    "                val_acc.append(accuracy)\n",
    "                pseudo_class = pd.Categorical([label_names[i] for i in dnn_predictions[-1].argmax(1)])\n",
    "                print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')} accuracy: {accuracy:.2f}% \\npseudo_class: {pseudo_class}\")\n",
    "            print(f\"  [{time.strftime('%Y-%m-%d %H:%M:%S')} total accuracy: {np.mean(val_acc):.2f}%\")\n",
    "\n",
    "\n",
    "class DNNDataset(Dataset):\n",
    "    def __init__(self, adata, ann_key, marker_genes=None):\n",
    "        self.adata = adata\n",
    "        self.shape = adata.shape\n",
    "        self.ann_key = ann_key\n",
    "        if sp.issparse(adata.X):\n",
    "            adata.X = adata.X.toarray()\n",
    "\n",
    "        if marker_genes is None:\n",
    "            data = adata.X\n",
    "        else:\n",
    "            gene_indices = adata.var_names.get_indexer(marker_genes)\n",
    "            data = np.pad(adata.X, ((0, 0), (0, 1)))[:, gene_indices].copy()\n",
    "\n",
    "        norm_factor = np.linalg.norm(data, axis=1, keepdims=True)\n",
    "        norm_factor[norm_factor == 0] = 1\n",
    "        self.data = data / norm_factor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx].squeeze()\n",
    "        y = self.adata.obs[self.ann_key].cat.codes[idx]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def transform_data_loader(adata, ann_key, marker_genes=None, batch_size=4096):\n",
    "    dataset = DNNDataset(adata, ann_key, marker_genes=marker_genes)\n",
    "    train_loader = DataLoader(dataset=dataset, batch_size=batch_size, drop_last=True, shuffle=True, num_workers=0)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "def dnn_workflow(data_path,\n",
    "                 ann_key,\n",
    "                 marker_genes=None,\n",
    "                 batch_size=4096,\n",
    "                 epochs=200,\n",
    "                 gpu=\"0\",\n",
    "                 model_name=\"dnn_CTX_cellbin.bgi\",\n",
    "                 model_path=\"./output\",\n",
    "                 filter_mt=False,\n",
    "                 cell_min_counts=300,\n",
    "                 gene_min_cells=10,\n",
    "                 cell_max_counts=98.):\n",
    "    \"\"\"\n",
    "    :param data_path: data path, which must be AnnData format.\n",
    "    :param ann_key: the annotation key in .obs.keys() list.\n",
    "    :param marker_genes: whether to use marker list data to train the model. If None, all data is used to train the model. Default, None.\n",
    "    :param batch_size:\n",
    "    :param epochs:\n",
    "    :param gpu: whether to use GPU training model. If None, the CPU training model is used. If it is number, the corresponding GPU training model is invoked.\n",
    "    :param model_name:\n",
    "    :param model_path: save dnn model path.\n",
    "    :param filter_mt: whether to filter MT- gene.\n",
    "    :param cell_min_counts:\n",
    "    :param gene_min_cells:\n",
    "    :param cell_max_counts: filter cell counts outliers.  If the value is 100, no filtering is performed. Range: (0, 100).\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    # assert data_path.endswith(\".h5ad\"), \"Error, Got an invalid DATA_PATH!\"\n",
    "    # adata = sc.read_h5ad(data_path)\n",
    "    adata = diopy.input.read_h5(data_path)\n",
    "    \n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    print(f\"  [Data Info] \\n {adata}\")\n",
    "    assert batch_size <= adata.shape[0], \"Error, Batch size cannot be larger than the data set row.\"\n",
    "\n",
    "    # if filter_mt:\n",
    "    #     adata.var[\"mt\"] = adata.var_names.str.startswith([\"MT-\", \"mt-\", \"Mt-\"])\n",
    "    #     sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "    #     adata = adata[adata.obs[\"pct_counts_mt\"] < 10].copy()\n",
    "    # if cell_min_counts > 0:\n",
    "    #     sc.pp.filter_cells(adata, min_counts=cell_min_counts)\n",
    "    if gene_min_cells > 0:\n",
    "        sc.pp.filter_genes(adata, min_cells=gene_min_cells)\n",
    "    # if cell_max_counts < 100:\n",
    "    #     max_count = np.percentile(adata.obs[\"nCount_RNA\"], cell_max_counts)\n",
    "    #     sc.pp.filter_cells(adata, max_counts=max_count)\n",
    "\n",
    "    print(f\"  [After Preprocessing Data Info] \\n {adata}\")\n",
    "    label_names = adata.obs[ann_key].cat.categories.tolist()\n",
    "    class_nums = len(adata.obs[ann_key].cat.categories)\n",
    "    if marker_genes is None:\n",
    "        marker_list = adata.var_names.tolist()\n",
    "    else:\n",
    "        marker_list = marker_genes\n",
    "\n",
    "    data_loader = transform_data_loader(adata, ann_key, marker_genes, batch_size)\n",
    "\n",
    "    trainer = DNNTrainer(input_dims=adata.shape[1],\n",
    "                         num_classes=len(adata.obs[ann_key].cat.categories),\n",
    "                         gpu=gpu)\n",
    "\n",
    "    trainer.train(data_loader, marker_genes=marker_list, class_nums=class_nums, batch_size=batch_size,\n",
    "                  label_names=label_names, epochs=epochs, path=osp.join(model_path, model_name))\n",
    "    trainer.validation(data_loader, osp.join(model_path, model_name))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    # 设置工作目录\n",
    "    working_dir = 'E:/doctor/自研/mapping/data/20230814final/h5/sc/'\n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    # 获取所有文件列表\n",
    "    datalist = [f for f in os.listdir() if os.path.isfile(f)]\n",
    "\n",
    "    # 循环遍历文件\n",
    "    for i in range(2, len(datalist)):\n",
    "    # for i in range(0, 1):\n",
    "        print(datalist[i])\n",
    "\n",
    "        # 读取st数据\n",
    "        sc_path = os.path.join(working_dir, datalist[i])\n",
    "       \n",
    "        # 根据st数据选取sc数据\n",
    "        if datalist[i] == \"sc_HIP\":\n",
    "#             sc_obj = diopy.input.read_h5(\"E:/doctor/自研/mapping/data/20230814final/h5/sc/sc_HIP.h5\")\n",
    "            ann_key = 'annotation'\n",
    "\n",
    "        elif datalist[i] == \"sc_CB.h5\":\n",
    "#             sc_obj = diopy.input.read_h5(\"E:/doctor/自研/mapping/data/20230814final/h5/sc/sc_CB.h5\")\n",
    "            ann_key = 'annotation'\n",
    "\n",
    "        elif datalist[i] == \"sc_OB.h5\":\n",
    "#             sc_obj = diopy.input.read_h5(\"E:/doctor/自研/mapping/data/20230814final/h5/sc/sc_OB.h5\")\n",
    "            ann_key = 'type'\n",
    "\n",
    "        elif datalist[i] == \"sc_human_CTX.h5\":\n",
    "#             sc_obj = diopy.input.read_h5(\"E:/doctor/自研/mapping/data/20230814final/h5/sc/sc_human_CTX.h5\")\n",
    "            ann_key = 'Subclass'\n",
    "\n",
    "\n",
    "        elif datalist[i] == \"sc_mouse_CTX.h5\":\n",
    "#             sc_obj = diopy.input.read_h5(\"E:/doctor/自研/mapping/data/20230814final/h5/sc/sc_mouse_CTX.h5\")\n",
    "            ann_key = 'Type'\n",
    "\n",
    "        start_time = time.time()\n",
    "        dnn_workflow(sc_path,\n",
    "                     ann_key,\n",
    "                     marker_genes=None,\n",
    "                     batch_size=100,\n",
    "                     epochs=100,\n",
    "                     gpu=\"0\",\n",
    "                     model_name=\"dnn_\"+datalist[i]+\".bgi\",\n",
    "                     model_path=\"E:/doctor/自研/mapping/data/20230814final/spatialID/model\",\n",
    "                     filter_mt=False,\n",
    "                     cell_min_counts=300,\n",
    "                     gene_min_cells=10,\n",
    "                     cell_max_counts=98.)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        time_diff = end_time-start_time\n",
    "        print(time_diff)\n",
    "\n",
    "        time_name=\"E:/doctor/自研/mapping/data/20230814final/result/spatialID/\"+datalist[i]+\"_spatialID_prediction_time.csv\"\n",
    "        pd.Series([time_diff], name='time_diff').to_csv(time_name, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae006e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_CB.h5\n",
      "sc_HIP.h5\n",
      "sc_human_CTX.h5\n",
      "sc_mouse_CTX.h5\n",
      "sc_OB.h5\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(datalist)):\n",
    "# for i in range(0, 1):\n",
    "    print(datalist[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4582e20d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sc_CB.h5', 'sc_HIP.h5', 'sc_human_CTX.h5', 'sc_mouse_CTX.h5', 'sc_OB.h5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03bd7f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "st_HIP_starmap.h5\n",
      "======> Loading data...\n",
      "  Original Data Info: 4632 cells × 5413 genes.\n",
      "  After Preprocessing Data Info: 4632 cells × 5413 genes.\n",
      "========> Transfering from sc-dataset...\n",
      "========> Model Training...\n",
      "std/n\n",
      "[1.0000015 1.0000418 0.9999959 ... 1.0000038 1.0000205 1.0000216]\n",
      "mean/n\n",
      "[ 3.9133138e-06  2.0202751e-06  1.7764295e-07 ...  3.6029228e-06\n",
      " -3.7510779e-06  1.5031241e-06]\n",
      "  [Epoch   1] Loss: 8.90255, Time: 0.14 s, Psuedo-Acc: 5.16%\n",
      "  [Epoch   2] Loss: 8.08281, Time: 0.27 s, Psuedo-Acc: 7.53%\n",
      "  [Epoch   3] Loss: 7.51573, Time: 0.41 s, Psuedo-Acc: 12.50%\n",
      "  [Epoch   4] Loss: 7.12634, Time: 0.53 s, Psuedo-Acc: 19.95%\n",
      "  [Epoch   5] Loss: 6.83398, Time: 0.65 s, Psuedo-Acc: 28.13%\n",
      "  [Epoch   6] Loss: 6.58420, Time: 0.79 s, Psuedo-Acc: 35.19%\n",
      "  [Epoch   7] Loss: 6.37379, Time: 0.92 s, Psuedo-Acc: 41.21%\n",
      "  [Epoch   8] Loss: 6.16213, Time: 1.04 s, Psuedo-Acc: 44.62%\n",
      "  [Epoch   9] Loss: 5.95993, Time: 1.17 s, Psuedo-Acc: 49.31%\n",
      "  [Epoch  10] Loss: 5.76960, Time: 1.31 s, Psuedo-Acc: 53.02%\n",
      "  [Epoch  11] Loss: 5.58425, Time: 1.44 s, Psuedo-Acc: 56.89%\n",
      "  [Epoch  12] Loss: 5.42982, Time: 1.57 s, Psuedo-Acc: 62.48%\n",
      "  [Epoch  13] Loss: 5.29722, Time: 1.70 s, Psuedo-Acc: 67.42%\n",
      "  [Epoch  14] Loss: 5.19548, Time: 1.84 s, Psuedo-Acc: 69.60%\n",
      "  [Epoch  15] Loss: 5.10094, Time: 1.98 s, Psuedo-Acc: 71.74%\n",
      "  [Epoch  16] Loss: 5.04694, Time: 2.12 s, Psuedo-Acc: 73.19%\n",
      "  [Epoch  17] Loss: 4.99261, Time: 2.25 s, Psuedo-Acc: 73.83%\n",
      "  [Epoch  18] Loss: 4.96343, Time: 2.40 s, Psuedo-Acc: 74.59%\n",
      "  [Epoch  19] Loss: 4.93227, Time: 2.53 s, Psuedo-Acc: 74.57%\n",
      "  [Epoch  20] Loss: 4.89923, Time: 2.69 s, Psuedo-Acc: 74.72%\n",
      "  [Epoch  21] Loss: 4.86869, Time: 2.85 s, Psuedo-Acc: 74.09%\n",
      "  [Epoch  22] Loss: 4.82619, Time: 3.01 s, Psuedo-Acc: 73.34%\n",
      "  [Epoch  23] Loss: 4.78453, Time: 3.19 s, Psuedo-Acc: 73.16%\n",
      "  [Epoch  24] Loss: 4.74193, Time: 3.36 s, Psuedo-Acc: 73.16%\n",
      "  [Epoch  25] Loss: 4.70174, Time: 3.52 s, Psuedo-Acc: 72.88%\n",
      "  [Epoch  26] Loss: 4.67175, Time: 3.68 s, Psuedo-Acc: 72.84%\n",
      "  [Epoch  27] Loss: 4.64097, Time: 3.86 s, Psuedo-Acc: 73.58%\n",
      "  [Epoch  28] Loss: 4.61122, Time: 4.02 s, Psuedo-Acc: 73.23%\n",
      "  [Epoch  29] Loss: 4.59689, Time: 4.19 s, Psuedo-Acc: 73.38%\n",
      "  [Epoch  30] Loss: 4.57837, Time: 4.35 s, Psuedo-Acc: 73.79%\n",
      "  [Epoch  31] Loss: 4.55465, Time: 4.53 s, Psuedo-Acc: 73.34%\n",
      "  [Epoch  32] Loss: 4.53021, Time: 4.69 s, Psuedo-Acc: 74.16%\n",
      "  [Epoch  33] Loss: 4.51225, Time: 4.86 s, Psuedo-Acc: 74.29%\n",
      "  [Epoch  34] Loss: 4.49432, Time: 5.03 s, Psuedo-Acc: 75.28%\n",
      "  [Epoch  35] Loss: 4.46955, Time: 5.19 s, Psuedo-Acc: 75.17%\n",
      "  [Epoch  36] Loss: 4.44265, Time: 5.35 s, Psuedo-Acc: 75.35%\n",
      "  [Epoch  37] Loss: 4.42883, Time: 5.50 s, Psuedo-Acc: 75.97%\n",
      "  [Epoch  38] Loss: 4.42191, Time: 5.69 s, Psuedo-Acc: 75.86%\n",
      "  [Epoch  39] Loss: 4.41187, Time: 5.84 s, Psuedo-Acc: 75.37%\n",
      "  [Epoch  40] Loss: 4.38789, Time: 6.01 s, Psuedo-Acc: 76.19%\n",
      "  [Epoch  41] Loss: 4.36923, Time: 6.17 s, Psuedo-Acc: 75.52%\n",
      "  [Epoch  42] Loss: 4.35775, Time: 6.33 s, Psuedo-Acc: 75.78%\n",
      "  [Epoch  43] Loss: 4.34753, Time: 6.51 s, Psuedo-Acc: 76.04%\n",
      "  [Epoch  44] Loss: 4.33337, Time: 6.67 s, Psuedo-Acc: 75.54%\n",
      "  [Epoch  45] Loss: 4.32256, Time: 6.83 s, Psuedo-Acc: 76.77%\n",
      "  [Epoch  46] Loss: 4.30116, Time: 7.01 s, Psuedo-Acc: 75.65%\n",
      "  [Epoch  47] Loss: 4.30385, Time: 7.17 s, Psuedo-Acc: 76.51%\n",
      "  [Epoch  48] Loss: 4.29555, Time: 7.34 s, Psuedo-Acc: 76.62%\n",
      "  [Epoch  49] Loss: 4.28433, Time: 7.50 s, Psuedo-Acc: 76.92%\n",
      "  [Epoch  50] Loss: 4.26570, Time: 7.68 s, Psuedo-Acc: 76.47%\n",
      "  [Epoch  51] Loss: 4.27753, Time: 7.86 s, Psuedo-Acc: 76.99%\n",
      "  [Epoch  52] Loss: 4.26835, Time: 8.05 s, Psuedo-Acc: 76.99%\n",
      "  [Epoch  53] Loss: 4.24912, Time: 8.22 s, Psuedo-Acc: 76.81%\n",
      "  [Epoch  54] Loss: 4.25219, Time: 8.37 s, Psuedo-Acc: 77.27%\n",
      "  [Epoch  55] Loss: 4.23738, Time: 8.54 s, Psuedo-Acc: 77.07%\n",
      "  [Epoch  56] Loss: 4.23625, Time: 8.70 s, Psuedo-Acc: 76.68%\n",
      "  [Epoch  57] Loss: 4.21958, Time: 8.87 s, Psuedo-Acc: 76.62%\n",
      "  [Epoch  58] Loss: 4.22511, Time: 9.02 s, Psuedo-Acc: 76.92%\n",
      "  [Epoch  59] Loss: 4.21319, Time: 9.19 s, Psuedo-Acc: 77.20%\n",
      "  [Epoch  60] Loss: 4.21603, Time: 9.35 s, Psuedo-Acc: 77.87%\n",
      "  [Epoch  61] Loss: 4.20690, Time: 9.50 s, Psuedo-Acc: 77.46%\n",
      "  [Epoch  62] Loss: 4.19505, Time: 9.66 s, Psuedo-Acc: 77.91%\n",
      "  [Epoch  63] Loss: 4.19149, Time: 9.83 s, Psuedo-Acc: 77.57%\n",
      "  [Epoch  64] Loss: 4.18058, Time: 10.00 s, Psuedo-Acc: 77.96%\n",
      "  [Epoch  65] Loss: 4.16664, Time: 10.17 s, Psuedo-Acc: 77.91%\n",
      "  [Epoch  66] Loss: 4.16742, Time: 10.33 s, Psuedo-Acc: 76.79%\n",
      "  [Epoch  67] Loss: 4.16186, Time: 10.50 s, Psuedo-Acc: 77.50%\n",
      "  [Epoch  68] Loss: 4.16707, Time: 10.67 s, Psuedo-Acc: 76.90%\n",
      "  [Epoch  69] Loss: 4.14681, Time: 10.83 s, Psuedo-Acc: 77.63%\n",
      "  [Epoch  70] Loss: 4.14889, Time: 11.02 s, Psuedo-Acc: 78.07%\n",
      "  [Epoch  71] Loss: 4.13833, Time: 11.18 s, Psuedo-Acc: 77.25%\n",
      "  [Epoch  72] Loss: 4.13370, Time: 11.33 s, Psuedo-Acc: 77.55%\n",
      "  [Epoch  73] Loss: 4.12063, Time: 11.51 s, Psuedo-Acc: 76.64%\n",
      "  [Epoch  74] Loss: 4.11217, Time: 11.68 s, Psuedo-Acc: 77.09%\n",
      "  [Epoch  75] Loss: 4.10644, Time: 11.83 s, Psuedo-Acc: 77.70%\n",
      "  [Epoch  76] Loss: 4.11295, Time: 12.00 s, Psuedo-Acc: 77.22%\n",
      "  [Epoch  77] Loss: 4.10010, Time: 12.17 s, Psuedo-Acc: 77.29%\n",
      "  [Epoch  78] Loss: 4.09965, Time: 12.33 s, Psuedo-Acc: 77.40%\n",
      "  [Epoch  79] Loss: 4.09859, Time: 12.50 s, Psuedo-Acc: 78.09%\n",
      "  [Epoch  80] Loss: 4.08579, Time: 12.68 s, Psuedo-Acc: 77.31%\n",
      "  [Epoch  81] Loss: 4.07693, Time: 12.83 s, Psuedo-Acc: 77.66%\n",
      "  [Epoch  82] Loss: 4.07112, Time: 13.01 s, Psuedo-Acc: 77.27%\n",
      "  [Epoch  83] Loss: 4.07529, Time: 13.17 s, Psuedo-Acc: 77.40%\n",
      "  [Epoch  84] Loss: 4.06082, Time: 13.34 s, Psuedo-Acc: 77.57%\n",
      "  [Epoch  85] Loss: 4.06209, Time: 13.51 s, Psuedo-Acc: 77.14%\n",
      "  [Epoch  86] Loss: 4.06277, Time: 13.68 s, Psuedo-Acc: 77.85%\n",
      "  [Epoch  87] Loss: 4.06269, Time: 13.86 s, Psuedo-Acc: 77.83%\n",
      "  [Epoch  88] Loss: 4.05534, Time: 14.02 s, Psuedo-Acc: 77.20%\n",
      "  [Epoch  89] Loss: 4.05299, Time: 14.19 s, Psuedo-Acc: 77.57%\n",
      "  [Epoch  90] Loss: 4.05485, Time: 14.36 s, Psuedo-Acc: 77.55%\n",
      "  [Epoch  91] Loss: 4.04369, Time: 14.53 s, Psuedo-Acc: 77.55%\n",
      "  [Epoch  92] Loss: 4.05196, Time: 14.71 s, Psuedo-Acc: 77.48%\n",
      "  [Epoch  93] Loss: 4.04619, Time: 14.91 s, Psuedo-Acc: 77.66%\n",
      "  [Epoch  94] Loss: 4.03735, Time: 15.09 s, Psuedo-Acc: 77.35%\n",
      "  [Epoch  95] Loss: 4.03220, Time: 15.26 s, Psuedo-Acc: 77.72%\n",
      "  [Epoch  96] Loss: 4.03447, Time: 15.43 s, Psuedo-Acc: 77.31%\n",
      "  [Epoch  97] Loss: 4.03022, Time: 15.60 s, Psuedo-Acc: 77.27%\n",
      "  [Epoch  98] Loss: 4.04023, Time: 15.77 s, Psuedo-Acc: 77.40%\n",
      "  [Epoch  99] Loss: 4.03064, Time: 15.95 s, Psuedo-Acc: 77.85%\n",
      "  [Epoch 100] Loss: 4.02550, Time: 16.12 s, Psuedo-Acc: 77.55%\n",
      "  [Epoch 101] Loss: 4.01186, Time: 16.29 s, Psuedo-Acc: 77.46%\n",
      "  [Epoch 102] Loss: 4.02156, Time: 16.45 s, Psuedo-Acc: 77.31%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 233\u001b[0m\n\u001b[0;32m    230\u001b[0m save_path_circle \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:/doctor/自研/mapping/data/20230814final/spatialID/result/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m datalist[i]\n\u001b[0;32m    232\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 233\u001b[0m \u001b[43mspatial_classification_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_path_circle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfilter_mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmin_cells\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmin_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mmax_percent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m98.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpca_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mk_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m39\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m                            \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mw_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mw_dae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mw_gae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdnn_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdnn_path_circle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path_circle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    250\u001b[0m time_diff \u001b[38;5;241m=\u001b[39m end_time\u001b[38;5;241m-\u001b[39mstart_time\n",
      "Cell \u001b[1;32mIn[11], line 191\u001b[0m, in \u001b[0;36mspatial_classification_tool\u001b[1;34m(data_path, filter_mt, min_cells, min_counts, max_percent, pca_dim, k_graph, edge_weight, epochs, w_cls, w_dae, w_gae, dnn_path, save_path, gpu)\u001b[0m\n\u001b[0;32m    187\u001b[0m adata \u001b[38;5;241m=\u001b[39m load_data(data_path, filter_mt\u001b[38;5;241m=\u001b[39mfilter_mt, min_cells\u001b[38;5;241m=\u001b[39mmin_cells, min_counts\u001b[38;5;241m=\u001b[39mmin_counts, max_percent\u001b[38;5;241m=\u001b[39mmax_percent)\n\u001b[0;32m    189\u001b[0m adata \u001b[38;5;241m=\u001b[39m transfer_from_sc_data(adata, dnn_path, gpu\u001b[38;5;241m=\u001b[39mgpu)\n\u001b[1;32m--> 191\u001b[0m \u001b[43mdistribution_fine_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43madata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpca_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpca_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw_dae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_dae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_gae\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw_gae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 149\u001b[0m, in \u001b[0;36mdistribution_fine_tune\u001b[1;34m(adata, pca_dim, k_graph, edge_weight, epochs, w_cls, w_dae, w_gae, gpu, save_path)\u001b[0m\n\u001b[0;32m    147\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(adata\u001b[38;5;241m.\u001b[39muns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsuedo_classes\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    148\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SpatialModelTrainer(input_dim, num_classes, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m--> 149\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_dae\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_gae\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# save_path=\"D:/博士/spatialid-main/SPATIALID/output/HIP_binsize\"\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# 不保存了吧\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m#trainer.save_checkpoint(osp.join(save_path+\"model.bgi\"))\u001b[39;00m\n\u001b[0;32m    154\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_checkpoint(save_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.bgi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\博士\\spatialid-main\\basic_model\\cell_type_ann_model.py:156\u001b[0m, in \u001b[0;36mSpatialModelTrainer.train\u001b[1;34m(self, data, epochs, w_cls, w_dae, w_gae)\u001b[0m\n\u001b[0;32m    154\u001b[0m edge_weight \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39medge_weight\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[1;32m--> 156\u001b[0m     outputs, dae_loss, gae_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m     loss \u001b[38;5;241m=\u001b[39m w_cls \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(outputs, targets) \u001b[38;5;241m+\u001b[39m w_dae \u001b[38;5;241m*\u001b[39m dae_loss \u001b[38;5;241m+\u001b[39m w_gae \u001b[38;5;241m*\u001b[39m gae_loss\n\u001b[0;32m    158\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\spatialIDnew\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\博士\\spatialid-main\\basic_model\\cell_type_ann_model.py:99\u001b[0m, in \u001b[0;36mSpatialModel.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m     97\u001b[0m x_dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(feat_x)\n\u001b[0;32m     98\u001b[0m dae_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(x_dec, x)\n\u001b[1;32m---> 99\u001b[0m gae_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecon_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat_g\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvgae\u001b[38;5;241m.\u001b[39mkl_loss()\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(feat)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m, dae_loss, gae_loss\n",
      "File \u001b[1;32mD:\\博士\\spatialid-main\\basic_model\\cell_type_ann_model.py:109\u001b[0m, in \u001b[0;36mSpatialModel.recon_loss\u001b[1;34m(self, z, edge_weight, pos_edge_index, neg_edge_index)\u001b[0m\n\u001b[0;32m    107\u001b[0m pos_edge_index, _ \u001b[38;5;241m=\u001b[39m add_self_loops(pos_edge_index)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neg_edge_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 109\u001b[0m     neg_edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mnegative_sampling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m neg_dec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvgae\u001b[38;5;241m.\u001b[39mdecoder(z, neg_edge_index, sigmoid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    111\u001b[0m neg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mF\u001b[38;5;241m.\u001b[39mlogsigmoid(\u001b[38;5;241m-\u001b[39mneg_dec)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\spatialIDnew\\lib\\site-packages\\torch_geometric\\utils\\negative_sampling.py:86\u001b[0m, in \u001b[0;36mnegative_sampling\u001b[1;34m(edge_index, num_nodes, num_neg_samples, method, force_undirected)\u001b[0m\n\u001b[0;32m     84\u001b[0m     mask \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misin(rnd, neg_idx\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     85\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mask)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)\n\u001b[1;32m---> 86\u001b[0m rnd \u001b[38;5;241m=\u001b[39m \u001b[43mrnd\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto(edge_index\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     87\u001b[0m neg_idx \u001b[38;5;241m=\u001b[39m rnd \u001b[38;5;28;01mif\u001b[39;00m neg_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([neg_idx, rnd])\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m neg_idx\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_neg_samples:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def load_data(data_path, filter_mt=True, min_cells=10, min_counts=300, max_percent=98.0):\n",
    "    \"\"\"\n",
    "    loading and processing dataset\n",
    "    :param data_path: Note that, the input data must be raw, can not do any preprocessing!\n",
    "    :param filter_mt: Whether to filter MT- genes. default, True\n",
    "    :param min_cells: Whether to filter genes. default, 10\n",
    "    :param min_counts: Whether to filter cells. default, 300\n",
    "    :param max_percent: Whether to filter cells, Range: (0, 100). default, 98.0\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"======> Loading data...\")\n",
    "    adata = diopy.input.read_h5(data_path)\n",
    "    # adata = sc.read_h5ad(data_path)\n",
    "    print('  Original Data Info: %d cells × %d genes.' % (adata.shape[0], adata.shape[1]))\n",
    "\n",
    "    # if filter_mt:\n",
    "    #     adata.var[\"mt\"] = adata.var_names.str.startswith((\"MT-\", \"Mt-\", \"mt-\"))\n",
    "    #     sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\"], inplace=True)\n",
    "    #     adata = adata[adata.obs[\"pct_counts_mt\"] < 10].copy()\n",
    "    # if min_counts > 0:\n",
    "    #     sc.pp.filter_cells(adata, min_counts=min_counts)\n",
    "    # if min_cells > 0:\n",
    "    #     sc.pp.filter_genes(adata, min_cells=min_cells)\n",
    "    # if max_percent < 100:\n",
    "    #     max_counts = np.percentile(adata.X.sum(1), max_percent)\n",
    "    #     sc.pp.filter_cells(adata, max_counts=max_counts)\n",
    "\n",
    "    # adata_X_sparse_backup = adata.X.copy()\n",
    "    print('  After Preprocessing Data Info: %d cells × %d genes.' % (adata.shape[0], adata.shape[1]))\n",
    "    if sp.issparse(adata.X):\n",
    "        adata.X = adata.X.toarray()\n",
    "    return adata\n",
    "\n",
    "\n",
    "def transfer_from_sc_data(adata, dnn_path, gpu=\"0\"):\n",
    "    \"\"\"\n",
    "    :param adata:\n",
    "    :param dnn_path: Pre-trained DNN model save path\n",
    "    :param gpu: gpu number\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(\"========> Transfering from sc-dataset...\")\n",
    "    if gpu is not None and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:{}\".format(gpu))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    checkpoint = torch.load(dnn_path)\n",
    "    dnn_model = checkpoint[\"model\"].to(device)\n",
    "    dnn_model.eval()\n",
    "\n",
    "    marker_genes = checkpoint[\"marker_genes\"]\n",
    "    gene_indices = adata.var_names.get_indexer(marker_genes)\n",
    "    adata_X = np.pad(adata.X, ((0, 0), (0, 1)))[:, gene_indices].copy()\n",
    "    norm_factor = np.linalg.norm(adata_X, axis=1, keepdims=True)\n",
    "    norm_factor[norm_factor == 0] = 1\n",
    "    dnn_inputs = torch.Tensor(adata_X / norm_factor).split(checkpoint[\"batch_size\"])\n",
    "    # Inference with DNN model.\n",
    "    dnn_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, inputs in enumerate(dnn_inputs):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = dnn_model(inputs)\n",
    "            dnn_predictions.append(outputs.detach().cpu().numpy())\n",
    "    label_names = checkpoint['label_names']\n",
    "    adata.obsm['psuedo_label'] = np.concatenate(dnn_predictions)\n",
    "    adata.obs['psuedo_class'] = pd.Categorical([label_names[i] for i in adata.obsm['psuedo_label'].argmax(1)])\n",
    "    adata.uns['psuedo_classes'] = label_names\n",
    "    return adata\n",
    "\n",
    "\n",
    "def distribution_fine_tune(adata, pca_dim=200, k_graph=30, edge_weight=True, epochs=200, w_cls=20, w_dae=1., w_gae=1.,\n",
    "                           gpu=\"0\", save_path=\"./output\"):\n",
    "    \"\"\"\n",
    "    :param adata:\n",
    "    :param pca_dim: PCA dims, default=200\n",
    "    :param k_graph: neighbors number, default=30\n",
    "    :param edge_weight: Add edge weight to the graph model, default=True\n",
    "    :param epochs: GCN training epochs, default=200\n",
    "    :param w_cls: class num weight, default=20\n",
    "    :param w_dae: dnn weight\n",
    "    :param w_gae: gcn weight\n",
    "    :param gpu: gpu number\n",
    "    :param save_path: results save path\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda:{}\".format(gpu))\n",
    "    # if gpu is not None and torch.cuda.is_available():\n",
    "    #     device = torch.device(\"cuda:{}\".format(gpu))\n",
    "    # else:\n",
    "    #     device = torch.device(\"cpu\")\n",
    "\n",
    "    print(\"========> Model Training...\")\n",
    "    sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    adata.X += 0.0001\n",
    "    adata.X = (adata.X - adata.X.mean(0)) / adata.X.std(0)\n",
    "    print(\"std/n\")\n",
    "    print(adata.X.std(0))\n",
    "    print(\"mean/n\")\n",
    "    print(adata.X.mean(0))\n",
    "    gene_mat = torch.Tensor(adata.X)\n",
    "\n",
    "    u, s, v = torch.pca_lowrank(gene_mat, pca_dim)\n",
    "    gene_mat = torch.matmul(gene_mat, v)\n",
    "    #tqy告诉我加的这个\n",
    "    \n",
    "    if datalist[i] in [\"st_HIP_starmap.h5\", \"C2D2_HIP_cellbin.h5\", \"C2D2_OB_cellbin.h5\", \"C2D2_CB_cellbin.h5\"]:\n",
    "        adata.obs[\"coor_x\"] = pd.to_numeric(adata.obs[\"coor_x\"], errors='coerce')\n",
    "        adata.obs[\"coor_y\"] = pd.to_numeric(adata.obs[\"coor_y\"], errors='coerce')\n",
    "        adata.obsm['spatial'] = np.array(pd.DataFrame({\"coor_x\": adata.obs[\"coor_x\"], \"coor_y\": adata.obs[\"coor_y\"]}))\n",
    "\n",
    "    elif datalist[i] in [\"st_human_CTX.h5\", \"st_mouse_CTX.h5\", \"HIP_slide_seq.h5\", \"HIP_test1.h5\"]:\n",
    "#         adata.obsm['spatial'] = np.array(pd.DataFrame({\"coor_x\": adata.obs[\"imagerow\"], \"coor_y\": adata.obs[\"imagecol\"]}))\n",
    "        adata.obs[\"imagerow\"] = pd.to_numeric(adata.obs[\"imagerow\"], errors='coerce')\n",
    "        adata.obs[\"imagecol\"] = pd.to_numeric(adata.obs[\"imagecol\"], errors='coerce')\n",
    "        adata.obsm['spatial'] = np.array(pd.DataFrame({\"coor_x\": adata.obs[\"imagerow\"], \"coor_y\": adata.obs[\"imagecol\"]}))\n",
    "\n",
    "\n",
    "    cell_coo = torch.Tensor(adata.obsm['spatial'])\n",
    "\n",
    "    # cell_coo = torch.Tensor(adata.obsm['X_spatial'])\n",
    "    data = torch_geometric.data.Data(x=gene_mat, pos=cell_coo)\n",
    "    data = torch_geometric.transforms.KNNGraph(k=k_graph, loop=True)(data)\n",
    "    data.y = torch.Tensor(adata.obsm['psuedo_label'])\n",
    "\n",
    "    # Make distances as edge weights.\n",
    "    if edge_weight:\n",
    "        data = torch_geometric.transforms.Distance()(data)\n",
    "        data.edge_weight = 1 - data.edge_attr[:, 0]\n",
    "    else:\n",
    "        data.edge_weight = torch.ones(data.edge_index.size(1))\n",
    "\n",
    "    # Train self-supervision model.\n",
    "    input_dim = data.num_features\n",
    "    num_classes = len(adata.uns['psuedo_classes'])\n",
    "    trainer = SpatialModelTrainer(input_dim, num_classes, device=device)\n",
    "    trainer.train(data, epochs, w_cls, w_dae, w_gae)\n",
    "\n",
    "    # save_path=\"D:/博士/spatialid-main/SPATIALID/output/HIP_binsize\"\n",
    "    # 不保存了吧\n",
    "    #trainer.save_checkpoint(osp.join(save_path+\"model.bgi\"))\n",
    "    trainer.save_checkpoint(save_path + \"model.bgi\")\n",
    "    # Inference.\n",
    "    print('\\n==> Inferencing...')\n",
    "    predictions = trainer.valid(data)\n",
    "    celltype_pred = pd.Categorical([adata.uns['psuedo_classes'][i] for i in predictions])\n",
    "\n",
    "    # Save results.\n",
    "    result = pd.DataFrame({'cell': adata.obs_names.tolist(), 'celltype_pred': celltype_pred})\n",
    "    #result.to_csv(osp.join(save_path, \"model.csv\"), index=False)\n",
    "    result.to_csv((save_path+\"model.csv\"), index=False)\n",
    "    adata.obs['celltype_pred'] = pd.Categorical(celltype_pred)\n",
    "    # adata.X = adata_X_sparse_backup\n",
    "\n",
    "    # # --------------------------------------------------\n",
    "    # adata.obsm[\"X_pca\"] = gene_mat.detach().cpu().numpy()\n",
    "    # #adata.write(osp.join(save_path, \"adata.h5ad\"))\n",
    "    #\n",
    "    # # Save visualization.\n",
    "    # spot_size = 30\n",
    "    # psuedo_top100 = adata.obs['psuedo_class'].to_numpy()\n",
    "    # other_classes = list(pd.value_counts(adata.obs['psuedo_class'])[100:].index)\n",
    "    # psuedo_top100[adata.obs['psuedo_class'].isin(other_classes)] = 'Others'\n",
    "    # adata.obs['psuedo_top100'] = pd.Categorical(psuedo_top100)\n",
    "    # sc.pl.spatial(adata, img_key=None, color=['psuedo_top100'], spot_size=spot_size, show=False)\n",
    "    # plt.savefig(osp.join(save_path, \"psuedo_top100.pdf\"), bbox_inches='tight', dpi=150)\n",
    "    # sc.pl.spatial(adata, img_key=None, color=['celltype_pred'], spot_size=spot_size, show=False)\n",
    "    # plt.savefig(osp.join(save_path, \"celltype_pred.pdf\"), bbox_inches='tight', dpi=150)\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "def spatial_classification_tool(data_path, filter_mt, min_cells, min_counts, max_percent, pca_dim,\n",
    "                                k_graph, edge_weight, epochs, w_cls, w_dae, w_gae,\n",
    "                                dnn_path, save_path, gpu=\"0\"):\n",
    "    adata = load_data(data_path, filter_mt=filter_mt, min_cells=min_cells, min_counts=min_counts, max_percent=max_percent)\n",
    "\n",
    "    adata = transfer_from_sc_data(adata, dnn_path, gpu=gpu)\n",
    "\n",
    "    distribution_fine_tune(adata, pca_dim=pca_dim, k_graph=k_graph, edge_weight=edge_weight, epochs=epochs, w_cls=w_cls,w_dae=w_dae, w_gae=w_gae, gpu=gpu, save_path=save_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 设置工作目录\n",
    "    working_dir = 'E:/doctor/自研/mapping/data/20230814final/h5/st/'\n",
    "    os.chdir(working_dir)\n",
    "\n",
    "    # 获取所有文件列表\n",
    "    datalist = [f for f in os.listdir() if os.path.isfile(f)]\n",
    "\n",
    "\n",
    "#     for i in range(0, len(datalist)):\n",
    "    for i in range(5, 6):\n",
    "        print(datalist[i])\n",
    "    # for i in range(6, 7):\n",
    "#         if(datalist[i]!=\"C2D2_HIP_cellbin.h5\"):\n",
    "#             continue\n",
    "        # 读取st数据\n",
    "        st_path = os.path.join(working_dir, datalist[i])\n",
    "        \n",
    "        # 根据st数据选取sc数据\n",
    "        if datalist[i] in [\"st_HIP_starmap.h5\", \"C2D2_HIP_cellbin.h5\", \"HIP_slide_seq.h5\", \"HIP_test1.h5\"]:\n",
    "            name_anno = 'sc_HIP.h5'\n",
    "\n",
    "        elif datalist[i] == \"C2D2_CB_cellbin.h5\":\n",
    "            name_anno = 'sc_CB.h5'\n",
    "\n",
    "        elif datalist[i] == \"C2D2_OB_cellbin.h5\":\n",
    "            name_anno = 'sc_OB.h5'\n",
    "\n",
    "        elif datalist[i] == \"st_human_CTX.h5\":\n",
    "            name_anno = 'sc_human_CTX.h5'\n",
    "\n",
    "        elif datalist[i] == \"st_mouse_CTX.h5\":\n",
    "            name_anno = 'sc_mouse_CTX.h5'\n",
    "            \n",
    "        data_path_circle = st_path\n",
    "        dnn_path_circle = \"E:/doctor/自研/mapping/data/20230814final/spatialID/model/\" + \"dnn_\"+name_anno+\".bgi\"\n",
    "        save_path_circle = \"E:/doctor/自研/mapping/data/20230814final/spatialID/result/\" + datalist[i]\n",
    "        \n",
    "        start_time = time.time()\n",
    "        spatial_classification_tool(data_path=data_path_circle,\n",
    "                                    filter_mt=False,\n",
    "                                    min_cells=10,\n",
    "                                    min_counts=200,\n",
    "                                    max_percent=98.,\n",
    "                                    pca_dim=50,\n",
    "                                    k_graph=39,\n",
    "                                    edge_weight=True,\n",
    "                                    epochs=500,\n",
    "                                    w_cls=20,\n",
    "                                    w_dae=1,\n",
    "                                    w_gae=1,\n",
    "                                    dnn_path=dnn_path_circle,\n",
    "                                    save_path=save_path_circle,\n",
    "                                    gpu=\"0\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        time_diff = end_time-start_time\n",
    "        print(time_diff)\n",
    "\n",
    "        time_name=\"E:/doctor/自研/mapping/data/20230814final/result/spatialID2/\"+datalist[i]+\"_spatialID_prediction_time.csv\"\n",
    "        pd.Series([time_diff], name='time_diff').to_csv(time_name, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c28c34aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C2D2_CB_cellbin.h5',\n",
       " 'C2D2_HIP_cellbin.h5',\n",
       " 'C2D2_OB_cellbin.h5',\n",
       " 'HIP_slide_seq.h5',\n",
       " 'HIP_test1.h5',\n",
       " 'st_HIP_starmap.h5',\n",
       " 'st_human_CTX.h5',\n",
       " 'st_mouse_CTX.h5']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74e02826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a5f017b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4632 × 5413\n",
       "    obs: 'orig.ident', 'nCount_RNA', 'nFeature_RNA', 'x', 'y', 'predict', 'celltype', 'coor_x', 'coor_y', 'celltype2'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata = diopy.input.read_h5(st_path)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a13a90e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "531b0455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "T_139116    24029\n",
       "T_139120    23534\n",
       "T_139142    23959\n",
       "T_139143    23339\n",
       "T_139144    23980\n",
       "            ...  \n",
       "T_169293    46211\n",
       "T_169294    46094\n",
       "T_169295    46054\n",
       "T_169297    45991\n",
       "T_169298    45884\n",
       "Name: coor_x, Length: 4632, dtype: category\n",
       "Categories (4215, object): ['22912', '23018', '23104', '23291', ..., '47464', '47466', '47470', '47483']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata.obs['coor_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789289d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.obs[\"coor_x\"] = adata.obs[\"coor_x\"].astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spatialIDEnv)",
   "language": "python",
   "name": "spatialidnew"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
